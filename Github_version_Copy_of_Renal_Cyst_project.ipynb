{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "language_info": {
            "name": "python"
        }
    },
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# Detecting Renal Cysts from CT Reports Using DistilBERT base model (uncased)\n",
                "\n",
                "\n",
                "In this project, I used the DistilBERT base model to classify CT reports based on the identification of renal cysts. For efficiency, I froze the model's pretrained weights and optimized only the head layer.\n"
            ],
            "metadata": {
                "id": "mh6VGTpktAlm"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 1. Load Dataset\n",
                "\n",
                "\n",
                "\n",
                "*   Load dataset from Google Drive\n",
                "*   Drop unnecessary features\n",
                "*   Check Data types\n"
            ],
            "metadata": {
                "id": "eAVIDhfYruw_"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "from google.colab import drive\n",
                "drive.mount('/content/drive')"
            ],
            "metadata": {
                "id": "AH70UtdwEah8"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "Bb4f75Lkq1iP"
            },
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "\n",
                "#load dataset\n",
                "data = pd.read_csv(\"path_to_your_dataset.csv\")\n",
                "\n",
                "#Drop unnessary features\n",
                "\n",
                "data=data.drop(['MRN','PRODUCT','PATIENT_WEIGHT','NATIONALITY','EPISODE_DATE','PATIENT_HEIGHT','Unnamed: 10','PATIENT_BMI'], axis=1)\n",
                "\n",
                "data.head()"
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "#check data type\n",
                "print(data.dtypes)"
            ],
            "metadata": {
                "id": "bKVojQCLRzYF"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "##  2. Preprocessing\n",
                "\n",
                "In this step:\n",
                "\n",
                "\n",
                "*   We convert datatypes for all columns\n",
                "*   We perfromed cleaning CT_REPORT\n",
                "*   We auto labeled data using regular expression since data is too large and was not labeld manually.\n",
                "\n",
                "\n"
            ],
            "metadata": {
                "id": "QpEbJpDfSH17"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "### Convert data types and remove Y from age column"
            ],
            "metadata": {
                "id": "W7xeUdyvHwGM"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# remove Y from age column\n",
                "data[\"PATIENT_AGE\"] = data[\"PATIENT_AGE\"].str.replace(\"Y\", \"\", regex=False)\n",
                "\n",
                "# convert data types\n",
                "data[\"PATIENT_AGE\"] = data[\"PATIENT_AGE\"].astype(int)\n",
                "data[\"PATIENT_GENDER\"] = data[\"PATIENT_GENDER\"].astype(str)\n",
                "data[\"CT_REPORT\"] = data[\"CT_REPORT\"].astype(str)\n",
                "\n",
                "# check data types\n",
                "print(data.dtypes)"
            ],
            "metadata": {
                "id": "ru4DwjGSSOWK"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "### Perfrom cleaning for CT REPORT"
            ],
            "metadata": {
                "id": "exuyu_5TH69s"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "import re\n",
                "\n",
                "\n",
                "def clean_ct_report(report):\n",
                "    \"\"\"\n",
                "    Cleans escape characters and unwanted spaces from a CT report.\n",
                "    \"\"\"\n",
                "    # remove newlines, tabs, and carriage returns and other noisy charcaters observed in the reports such as \\T\\\n",
                "    report = report.replace(\"\n\", \" \").replace(\"\t\", \" \").replace(\"\r\", \" \").replace(\"\\T\\\\\", \" \")\n",
                "\n",
                "    # this extra step to remove Unicode escape sequences, if any\n",
                "    report = re.sub(r\"\\\\u[0-9A-Fa-f]{4}\", \"\", report)  # Matches \\uXXXX\n",
                "    report = re.sub(r\"\\\\x[0-9A-Fa-f]{2}\", \"\", report)  # Matches \\xXX\n",
                "\n",
                "    # replace multiple spaces with a single space, if any\n",
                "    report = re.sub(r\"\\s+\", \" \", report)\n",
                "\n",
                "    # strip leading and trailing spaces, if any\n",
                "    report = report.strip()\n",
                "\n",
                "    return report\n",
                "\n",
                "# apply cleaning\n",
                "data[\"CT_REPORT\"] = data[\"CT_REPORT\"].apply(clean_ct_report)\n",
                "\n",
                "print(data)"
            ],
            "metadata": {
                "id": "78Qb0138DRaF"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "### Auto labeling data\n",
                "Since data is large and is not labeled, I used rule-based approach forlabeling data using regular expression where (1: renal cyst, 0: no renal cyst)\n",
                "\n",
                "\n",
                "\n",
                "\n"
            ],
            "metadata": {
                "id": "oqCcC3nIOOuv"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# Define a labeling function\n",
                "def contains_renal_cyst(text):\n",
                "    return 1 if re.search(r\"\brenal cyst\b\", text, re.IGNORECASE) else 0\n",
                "\n",
                "# Apply the function to create label\n",
                "data[\"label\"] = data[\"CT_REPORT\"].apply(contains_renal_cyst)\n",
                "\n",
                "print(data)\n"
            ],
            "metadata": {
                "id": "EltdKRPLO-lO"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Filter records with label=1 to check labeling\n",
                "data_filtered = data[data['label'] == 1]\n",
                "print(data_filtered)"
            ],
            "metadata": {
                "id": "AtR3PM8NG5jF"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 3. Prparing For Model Training\n",
                "\n",
                "\n",
                "\n",
                "*   Split dataset into train-test, with 40% for testing\n",
                "*   Define model and toeknizer\n",
                "*   Tokenize data\n",
                "\n",
                "\n"
            ],
            "metadata": {
                "id": "LQuC6e74Dssk"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "### Split data set for train-test"
            ],
            "metadata": {
                "id": "ucfq-lb7lhge"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "# split the dataset for train-test\n",
                "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
                "    data[\"CT_REPORT\"].tolist(),\n",
                "    data[\"label\"].tolist(),\n",
                "    test_size=0.4,\n",
                "    stratify=data[\"label\"],\n",
                "    random_state=42,\n",
                ")\n"
            ],
            "metadata": {
                "id": "20tGgcpGBgmf"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "### Define Model and Tokenizer\n",
                "\n"
            ],
            "metadata": {
                "id": "OFktENuoI2Zh"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
                "from torch.utils.data import DataLoader\n",
                "import torch\n",
                "\n",
                "# load the pre-trained model and tokenizer\n",
                "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
                "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2, id2label={0: \"no renal cyst\", 1: \"renal cyst\"},\n",
                "    label2id={\"no renal cyst\": 0, \"renal cyst\": 1})\n",
                "\n",
                "\n",
                "# freeze weights of the pre-trained model\n",
                "for param in model.base_model.parameters():\n",
                "    param.requires_grad = False\n",
                "\n",
                "print(model)\n"
            ],
            "metadata": {
                "id": "RiL1jnELYmO4"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "### Tokenize data"
            ],
            "metadata": {
                "id": "mTIMOnOlPJZD"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "from torch.utils.data import Dataset\n",
                "\n",
                "# Tokenize the data\n",
                "def tokenize_data(texts, labels):\n",
                "    tokens = tokenizer(\n",
                "        texts,\n",
                "        padding=True,\n",
                "        truncation=True,\n",
                "        max_length=512,\n",
                "        return_tensors=\"pt\",\n",
                "    )\n",
                "    tokens[\"labels\"] = torch.tensor(labels)  # Add labels to the tokens\n",
                "    return tokens\n",
                "\n",
                "# Custom Dataset Class\n",
                "class CTReportDataset(Dataset):\n",
                "    def __init__(self, texts, labels):\n",
                "        self.texts = texts\n",
                "        self.labels = labels\n",
                "        self.encodings = tokenize_data(texts, labels)\n",
                "\n",
                "    def __len__(self):\n",
                "        return len(self.labels)\n",
                "\n",
                "    def __getitem__(self, idx):\n",
                "        return {key: val[idx] for key, val in self.encodings.items()}\n",
                "\n",
                "# Prepare datasets\n",
                "train_dataset = CTReportDataset(train_texts, train_labels)\n",
                "test_dataset = CTReportDataset(test_texts, test_labels)\n"
            ],
            "metadata": {
                "id": "5Yf3CiQmCO51"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 4. Training Setup and Execution"
            ],
            "metadata": {
                "id": "KfySzsDYk-WL"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "from transformers import Trainer,TrainingArguments,DataCollatorWithPadding\n",
                "import numpy as np\n",
                "from sklearn.metrics import accuracy_score\n",
                "\n",
                "\n",
                "def compute_metrics(eval_pred):\n",
                "    predictions, labels = eval_pred\n",
                "    predictions = np.argmax(predictions, axis=1)\n",
                "    return {\"accuracy\": (predictions == labels).mean()}\n",
                "\n",
                "\n",
                "# training arguments\n",
                "training_args = TrainingArguments(\n",
                "    output_dir=\"./results\",\n",
                "    eval_strategy=\"epoch\",\n",
                "    learning_rate=2e-5,\n",
                "    per_device_train_batch_size=16,\n",
                "    per_device_eval_batch_size=16,\n",
                "    num_train_epochs=2,\n",
                "    weight_decay=0.01,\n",
                "    save_strategy=\"epoch\",\n",
                "    load_best_model_at_end=True,\n",
                ")\n",
                "\n",
                "\n",
                "trainer = Trainer(\n",
                "    model=model,\n",
                "    args=training_args,\n",
                "    train_dataset=train_dataset,\n",
                "    eval_dataset=test_dataset,\n",
                "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
                "    compute_metrics=compute_metrics\n",
                ")\n",
                "\n",
                "trainer.train()"
            ],
            "metadata": {
                "id": "bMxLGG8VWB7I"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 5. Model Evaluation"
            ],
            "metadata": {
                "id": "sOxkD5tfQMgz"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "results = trainer.evaluate()\n",
                "print(results)"
            ],
            "metadata": {
                "id": "MsgA-jLgQO75"
            },
            "execution_count": null,
            "outputs": []
        }
    ]
}
